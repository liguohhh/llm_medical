设计思路
Python与大模型对接的后端
Fastapi实现
使用sqlite存储数据
与springboot业务端交互时要鉴权（暂时不实现鉴权，但要留出接口）
内部实现全异步，支持并发
由springboot在发送chat请求的同时提供使用的模型，地址与apikey，python只需要调用这些key
Python内维护一个大模型
不同提示词以json形式保留在python后端，python提供一系列接口管理json提示词
Python接受请求后拼接提示词
拼接时除了使用系统提示词还要有rag内容
拼接提示词时有向量数据库rag（使用成熟方案）和自己维护的一个精确数据库（自设计方案，类似正则表达式等方案从用户输入内容中匹配，例如输入感冒能够查询到相关内容）
Python提供接口让springboot业务端能够操作这两种rag形式
Python提供流式的与大模型交互的相关接口

# 文件结构
.
├── main.py                 # FastAPI入口
├── config.py               # 配置文件
├── database/               # 数据库相关
│   ├── rag_db.py           # RAG数据库操作
│   └── sqlite_conn.py      # SQLite异步连接
├── auth/                   # 鉴权模块
│   └── jwt_handler.py      
├── prompts/                # 提示词管理
│   ├── prompt_manager.py
│   └── templates/         # 默认提示词JSON文件
├── rag/                    # RAG核心模块
│   ├── vector_rag.py       # 向量数据库实现
│   └── precise_rag.py      # 精确匹配实现
└── utils/                  # 工具类
    └── async_utils.py

/routers  #路由实现


向量数据库查询内容使用ChromaDB 实现，分为以下几个模块
1.VectorRAG
完善现有vector_rag内的VectorRAG类，提供初始化，操作chromadb的相关功能，持久化存储在现有的database文件夹内。
2.router
设计一个专门的vector_router提供一下接口，并提供接口文档
（1）新建/添加，调用相关services，用户上传txt/doc/pdf/docx等格式的文件，并指定对应的ChromaDB的namespace，（在serveice中将数据切分传入，单个txt，doc等切分后存入一个namespace下，使用同一个）最终返回该文档对应的namespace与负责标记该文档的metadata字段标记该文档的metadata字段
（2）删除，调用相关services，可以指定namespace删除整个namespace，或者传入指定标记单个文档的metadata字段与namespace，删除该namespace下的单个文档的所有切分（通过标记）
（3）查询，调用相关services，返回所有的namespace与每个namespace内所有的不同的标记文档的标记
3.services
（1）新建/添加，使用VectorRAG类，在services中负责格式化读取并切分用户传入的文件，并进行滑动窗口切分（滑动窗口可调节），将切分后的文档存入对应的namespace中，并打上对应的标记该文档的metadata字段，并返回该字段
（2）删除，使用VectorRAG类，可以指定namespace删除整个namespace，或者传入指定标记单个文档的metadata字段与namespace，删除该namespace下的单个文档的所有切分（通过标记）
（3）查询，使用VectorRAG类，返回所有的namespace与每个namespace内所有的不同的标记文档的标记
5.rag_service
重构rag_service，使其能够适配现在实现的功能，提供真正的search服务
4.chat_router，chat_service等
用户正常对话时，接口新增传入namespace（可以传入多个）与指定搜索数量（有默认值），使用rag_service搜索这些namespace的内容，并把最多n（搜索深度）个内容合并进入prompt
6.test
在test中新建一个test_vector，运行可以测试相关功能

最终：当全部完成时，当llm与用户正常对话时，应该能够自动检索相关向量数据库合并进入prompt


精准查询，使用sqlalchemy，目前连接sqlite数据库，sqlite创建并存储在/database内，满足异步需求
1.精确查询分很多大类，如感冒类，头疼类等，每个类中有很多掉条，每条有一个描述，不定数量个匹配词（负责查找匹配），具体内容（可能是几十几百字的长文本），权重（0-99的整数），是否启用，根据以上内容设计数据库，并在models中实现相关的py代码
2.routers
设计一个专门的precise_router提供以下接口，并提供接口文档
（1）新建一个大类，传入一个大类名，传入services中进行处理
（2）新建一个条目，传入一个大类的uid与一整条精确查询数据包含传入描述，内容，权重，n个关键词，传入services中进行处理
（3）删除一个大类，传入一个大类的uid，传入services中进行处理
（4）修改一个大类名，传入一个大类的uid与新的名字，传入services中进行处理
（5）修改一个条目，传入一个uid与一整条精确查询数据包含传入描述，内容，权重，n个关键词，传入services中进行处理
（6）列出所有大类，返回一个包含所有的大类名与uid的json
 (7) 列出所有小类，传入一个大类uid，这个大类下所有小类的所有数据
 3.precise_services
设计一个专门的precise_service提供以下接口，并提供接口文档
（1）新建一个大类，传入一个大类名，调用models中相关代码初始化大类
（2）新建一个条目，传入一个大类的uid与一整条精确查询数据包含传入描述，内容，权重，n个关键词，调用models中相关代码初始化条目
（3）删除一个大类，传入一个大类的uid，调用models中相关代码删除大类
（4）修改一个大类名，传入一个大类的uid与新的名字，调用models中相关代码修改
（5）修改一个条目，传入一个uid与一整条精确查询数据包含传入描述，内容，权重，n个关键词，传入services中进行处理调用models中相关代码修改
（6）列出所有大类，返回一个包含所有的大类名与uid的json
 (7) 列出所有小类，传入一个大类uid，这个大类下所有小类的所有数据
 3.chat_router
 让chat_router能够接受相关参数（可选，有默认值），参数有指定的n个搜索大类（不提供此项就不进行搜索），指定搜索数量（有默认值），搜索深度（有默认值），并传入service处理
 3.chat_service，precise_service与rag_service
 让rag_service能够真正调用precise_service的search
 实现原理为，1.用户传入搜索内容，指定搜索数量（有默认值），搜索深度（有默认值）
 2.使用分词将搜索内容进行拆分，拆分成一个个词语
 3.用词语在相关大类的匹配词中进行搜索，找到匹配的小条目
 3.将每个小条目的具体内容再拆分成词语（排除该小条目自身的匹配词），在该小条目所属的大类的匹配词中进行搜索
 4.根据传入的搜索深度决定搜索几次，如果传入深度为1，就是不进行再次拆分，只进行初次搜索
 5.将查询到的所有条目按照权重从大到小排序，取前n条（n为传入的搜索数量）作为搜索内容组合被rag_service调用并最终组合进入prompt中
 6.test
在test中新建一个test_precise，运行可以测试相关功能